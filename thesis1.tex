\input{report-header.tex}
\renewcommand{\clearpage}{}
\begin{document}

\section{Введение}
Существуют задачи, решение которых может быть сведено к решению СЛАУ большого размера с разреженной матрицей некоторого вида. К подобным задачам, например, относится поиск численного решения дифференциального уравнения или численный расчет параметров сложных электрических цепей. Для наиболее часто встречающихся видов матриц, таких как, трех- или пятидиагональных, блочно-диагональных, уже разработаны собственные оптимизации, позволяющие решить СЛАУ быстрее, чем за квадратичное время от числа неизвестных, вплоть до линейного. Однако в случае, если постановка задачи не может быть сведена математическими преобразованиями ни к одному из оптимальных с точки зрения вычислительной сложности решения видов, приходится или ограничиваться медленными классическими методами, не зависящими от структуры матрицы, или строить грубое начальное приближение исходной матрицы и приближать ее решение к искомому итерационными методами. Как правило, такое начальное приближение получается некоторыми структурными преобразованиями исходной матрицы, например занулением определенных областей в методе получения неполного LU разложения, что отражается на точности начального приближения решения СЛАУ. Предполагается, что использование методов, учитывающих качественные характеристики данных, содержащихся в матрице, может позволить построить более точную аппроксимацию исходной матрицы необходимого вида и таким образом уменьшить необходимое число итераций для получения искомого решения СЛАУ с заданной точностью.

\section{Методы решения СЛАУ}
В первую очередь, методы решения СЛАУ могут быть разделены на решающие СЛАУ общего и частного вида. Методы решения СЛАУ частного вида не рассматриваются в данной работе, т.к. уже имеют достаточное число методов решения, специфичных для каждого из случаев, в общем случае выполняющихся быстрее любого из общих методов решения СЛАУ. Очевидно, что методы решения СЛАУ частного вида не могут быть эффективно применены в задачах с матрицей, не приводимому к необходимому виду, что и составляет их основное ограничение. В свою очередь, методы решения СЛАУ общего вида как правило работают медленнее методов для решения СЛАУ частного вида, однако являются универсальными и по этой причине рассматриваются в этой работе.

Во-вторых, методы решения СЛАУ могут быть разделены на методы учитывающие и не учитывающие разреженность СЛАУ. Те методы, которые учитывают разреженность, позволяют находить эффективное с точки зрения используемой для хранения матрицы СЛАУ памяти в процессе вычисления решение. В свою очередь, методы не учитывающие разреженность, являются сложными в применении для СЛАУ большого размера, т.к. могут потребовать квадратичного объема памяти в зависимости от числа неизвестных.

Наконец, методы рещения СЛАУ могут быть разделены две основные группы -- прямые и итерационные. Прямые методы позволяют получить точное аналитическое решение однако как правило имеют высокую вычислительную сложность. Итерационные методы, в свою очередь, в некоторых случаях позволяют получить решение быстрее прямых методов, которое в большинстве случаев является лишь приближением точного решения СЛАУ с заданной точностью, а также могут иметь условную сходимость.

\subsection{Итерационные методы}
Основной идеей современных итерационных методов приближенного и точного решения СЛАУ является представление задачи поиска решения системы уравнений
\begin{equation*}
  \mathbf{A}\mathbf{x} = \mathbf{b}, \mathbf{A} \in \mathbb{C}_{n \times n},
 \end{equation*}
как минимума функции 
\begin{equation*}
  \Psi(\mathbf{x}) = \frac{1}{2}\mathbf{x}^H \mathbf{A} \mathbf{x} - \mathbf{b}^H \mathbf{x} + \gamma
\end{equation*}
на пространстве Крылова 
\begin{equation*}
  K_n(\mathbf{A}, \mathbf{v}) = span\left\{ \mathbf{v}, \mathbf{A}\mathbf{v}, ..., \mathbf{A}^{n-1}\mathbf{v} \right\}. 
\end{equation*}
Минимизация производится по методу градиентного спуска, где $\nabla\Psi(\mathbf{x}) = \mathbf{A}\mathbf{x} - \mathbf{b}$. В качестве крыловского пространства используется $K_n(\mathbf{A}, \mathbf{r}_0)$, где $\mathbf{r}_i = \mathbf{b} - \mathbf{A}\mathbf{x}_i, i \in [0, n-1]$, $\mathbf{x}_0$ - начальное приближение решения СЛАУ. Такой подход позволяет найти приближенное решение СЛАУ $\mathbf{x}_n \simeq \mathbf{x}^*$ как линейную комбинацию векторов линейной оболочки крыловского пространства, т.е. $\mathbf{x}_n \in \mathbf{x}_0 + K_n(\mathbf{A}, \mathbf{r}_0)$.


Основным различием итерационных методов решения СЛАУ является процесс построения $K_{i+1}(\mathbf{A}, \mathbf{r}_0)$, при котором $\mathbf{r}_{i+1}$ строится на основе выбора направления градиентного спуска(для семейства GC методов) или минимизации $\mathbf{A}$-нормы $\mathbf{x}_{i+1}$, где $||\mathbf{v}||_A = \sqrt{\mathbf{v}^H \mathbf{A} \mathbf{v}}$, для MinRES, GMRES.


Единственным итерационным методом, сходящимся к точному решению СЛАУ за не более чем $2n$ итераций является метод GMRES~\cite{krylovOverview}. Несмотря на реальную высокую скорость сходимости ($n_{real} \ll 2n$)~\cite{baseIDRs}, этот метод требует полного перестроения ортогонального базиса крыловского пространства на каждой итерации, что приводит к существенным затратам по времени выполнения и используемой памяти. Однако, вне зависимости от вычислительной сложности, этот метод может быть использован для оценки эффективности работы разрабатываемого метода по числу итераций.


Наиболее оптимальным с точки зрения числа требуемых итераций и вычислительных затрат на одну итерацию является метод IDR(s), в основе которого лежит выбор $\mathbf{r}_i$ таким образом, что $\mathbf{r}_i \in K_{i}, K_{j} \subseteq K_{j-1} \forall j \in [1, j]$. Благодаря такому выбору очередного вектора линейной оболочки, происходит понижение размерности крыловского пространства, реально необходимого для вычисления приближенного решения СЛАУ с заданной точностью. Алгоритм поиска решения по методу IDR(s) имеет вычислительную сложность порядка $O(n + \frac{n}{s})$~\cite{baseIDRs, advancedIDRs}, что выигрывает у прочих итерационных методов, в случае $s > 1$.


С точки зрения исследования, наиболее интересной задачей является предобуславливание матрицы для приведения ее виду, удобному для применения одного из итерационных методов. Выбор правильного предобуславливателя является залогом получения решения с заданной точностью за малое число итераций, а также получения наиболее точного начального приближения решения. Предобуславаливатели могут быть ``количественными'', т.е. такими, которые позволяют получить начальное приближение искомого вида засчет исключения части элементов из матрицы не основываясь при этом на самих данных, содержащихся в матрице, и ``качетсвенными'', т.е. такими, которые способны получить начальное приближение так же путем исключения некоторых элементов, но на основе анализа информации, содержащейся в матрице. Примерами количественных предобуславливателей являются неполное LU-разложение или получение верхнетреугольной матрицы путем отбрасывания элементов ниже главной диагонали, качетсвенные же предобуслаадиватели не так распространены, однако хорошим примером является SVD-разложение матрицы. Поиск качественного предобуславливателя, способного получить искомый вид матрицы за приемлемое (как минимум субквадратичное) время является одним из направлений исследования данной работы.


\subsection{Прямые методы}
Среди прямых методов решения разреженных СЛАУ большого размера наиболее оптимальной по вычислительно сложности и необходимой памяти является группа HSS методов. Основной идеей HSS метода является иерархическое представление матрицы в виде оптимального бинарного дерева блоков небольшого размера, например $4 \times 4$, через операции над которыми могут быть выражены остальные блоки, составляющие матрицу. Рекурсивному разложению подвергаются только блоки, размера $2n \times 2n$, стоящие на главной диагонали, оставшиеся части матрицы в строке или стоблце выражаются через операции композиции этих блоков. Представление матрицы подобным образом позволяет быстро~\cite{baseHSS} построить разложение Холецкого для матрицы $\mathbf{A} = \mathbf{L}\mathbf{L}^H$, что позволяет тривиально решить $\mathbf{A}\mathbf{x} = \mathbf{b}$, как $\mathbf{L}\mathbf{y} = \mathbf{b}, \mathbf{L}^H\mathbf{x} = \mathbf{y}$.


Прямые методы имеют значительное преимущество над итерационными, т.к. в результате приводят к точному решению СЛАУ и не имеют дополнительных условий на вид матрицы для работы алгоритма. Одним из направлений исследования в данной работе является использование методов кластеризации для ускорения построения иерархического представления матрицы по алгоритму HSS, т.к. вычисление этого представления в общем случае является более трудоемким ($O(n^2)$ в худшем случае, $O(n)$ -- в лучшем), чем собственно вычисление решения СЛАУ. Применение метода HSS так же является предпочтительным, т.к. вследствие использования иерархического представления с рекурсивным выражением блоков, через блоки нижнего уровня, требуется минимальный среди всех предложенных методов решения разреженной СЛАУ объем памяти для ее хранения в процессе работы алгоритма.


\section{Методы кластеризации}
В связи с тем, что как для прямых, так и для итерационных методов решения СЛАУ в качетсве направления исследования выбрано качетсвенное приведение матрицы к необходимому виду следует подробнее рассмотреть виды разложений матриц и методы кластеризации данных.

\subsection{Сингулярное разложение}
Сингулярное разложение -- это разложение прямоугольной матрицы $A$ вида $A = U \Sigma V^*$, где $U$ и $V$ -- унитарные матрицы, а $\Sigma$ -- матрица сингулярных чисел, представляющая наибольший интерес. Одним из наиболее важных свойств сингулярноего разложения является то, что на его основе можно получить приближение исходной матрицы, матрицей меньшего размера (и ранга). В этом случае, строки или столбцы отвечающие сингулярным числам, меньшим некоторого значения, удаляются из матриц $U, V$ и $\Sigma$, и искомое приближение принимает вид $A' = U' \Sigma' V'$, где $A'$ имеет меньший ранг, чем $A$, а также является наилучшим низкоранговым приближением исходной матрицы, согласно теореме Эккарта-Янга, что делает использование этого метода наиболее предпочтительным с точки зрения использования как предобуславаливателя для сведения матрицы к необходимому виду.


Основной проблемой этого разложения являтся высокая вычислительная сложность его вычисления -- для матрицы $A_{m \times n}$ оно имеет порядок $O\left(\alpha \cdot \max(mn^2, nm^2) \right)$, что для квадратной матрицы выливается в кубическую сложность относительно числа неизвестных. В настоящее время существует несколько алгоритмов~\cite{fastSVD, fitSVD}, способных вычислить это разложение при $5 < \alpha < 8$, что не меняет порядка вычислительной сложности. С точки зрения проблемы получения более качественного начального приближения для некоторого итерационного алгоритма, представляется возможным вычисление неполного SVD-разложения, т.е. вычисления только определенного числа сингулярных векторов и значений. Существует несколько алгоритмов, позволяющих получать итерационное приближение SVD-разложения с заданным искомым числом векторов в том числе и для разреженных матриц большого размера~\cite{krylovShurIterSVD, blockKrylovIterSVD, twoIterSVD, quicIterSVD, noisyIterSVD}. Предобуславливание матриц при помощи таких алгоритмов является одним из направлений исследования, как подзадача поиска качественного предобуславаливателя для некоторого итерационного алгоитма решения СЛАУ.


\nocite{*}
\addcontentsline{toc}{section}{Список литературы}
\section*{Список литературы}
\printbibliography[heading=none]
\end{document}